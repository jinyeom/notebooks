{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Models\n",
    "**Jin Yeom**  \n",
    "jin.yeom@hudl.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from pprint import pprint\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation as anime\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "from torch import nn, distributions\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements **[World Models](https://arxiv.org/abs/1803.10122)** (Ha & Schmidhuber, 2018). This work proposes a framework of model-based deep reinforcement learning. Two key differences in this work from more commonly seen deep RL algorithms (e.g., DQN, PPO, DDPG, etc.) are that 1) feature learning is separated from the controller, i.e., a world model agent isn't trained with a strange scheme of learning where it can only learn to see via reward signals, and 2) the agent's model is trained in an unsupervised fashion from its trajectory data; once trained, it can simulate the environment within a latent space (they describe this simulation as \"dreaming\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed agent consists of three components: the vision model ($V$) and the memory model ($M$), which together define the agent's world model, and a controller ($C$) for selecting actions. Ha and Schmidhuber chose to use a convolutional VAE for $V$ and a mixture density recurrent network for $M$, and a single layered network for $C$, which was evolved via CMA-ES. Note that their choice of architecture is more of a proof of concept and can be enhanced with more advanced algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this notebook is going to be a long one, i.e., this work is a sort of an orchestra of works that have shown progress over the past few years: unsupervised learning for images, temporal prediciton and reinforcement learning. This means that we'll be implementing three different models, and then some more to put them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with something simple: **Atari 2600 Pong**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM4AAAD8CAYAAAA/rZtiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA3xJREFUeJzt3DFu02AYgGEbRWp3Bg7RCzCy9SSMrNyha9eepFvHHAAOkSF7O5kJJFCK6lcJttHzbFFU9Vteffml3x6naRqAed4tPQBskXAgEA4EwoFAOBAIBwLhQCAcCIQDwW7pAYZhGMZx/Ov1hS9fb/7VKPDL/d238bXvVhHOGsP4/Gn+TA9P3y8wyfY9vzzO/pvrq9sLTHI+fqpBIBwIhAPBKs44W3Dq/FLOQZw+v5Rz0JJsHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBC55vpELneeztQudp9g4EAgHAuFA4IzzCi/eOJ+1v3ijsHEgEA4Eq/iptj8clx4BZrFxIBAOBMKBQDgQCAcC4UAgHAiEA4FwIFjFzYGPH94vPQLMYuNAIBwIhAOBcCAQDgTCgUA4EAgHAuFAIBwIhAPBqsLZH47eeMMmrCoc2ArhQCAcCFbxPM5PnsthK2wcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQLBbegA4h+eXx98+X1/dXvT/2TgQCAcC4UAgHAiEA4FwIBAOBMKBQDgQCAcC4UAgHAiEA4FwIBAOBJ7H4b9w6edv/mTjQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAgEA4EwoFAOBAIBwLhQCAcCIQDgXAg2C09wDAMw/5wXHoEmMXGgUA4EAgHAuFAIBwIhAOBcCAQDgTCgUA4EAgHAuFAIBwIhAOBcCAQDgTjNE1LzwCbY+NAIBwIhAOBcCAQDgTCgUA4EAgHAuFAIBwIhAOBcCAQDgTCgUA4EAgHAuFAIBwIhAOBcCAQDgTCgUA4EPwAypstp0s346gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('PongNoFrameskip-v4')\n",
    "obs = env.reset()\n",
    "plt.imshow(obs)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working with the environment, we'll preprocess the observation a little bit. Particularly, I think the scoreboard on top of the screen is rather irrelevant, so we'll crop it out; same for the bottom block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env, size):\n",
    "        super(ProcessFrame, self).__init__(env)\n",
    "        self.size = size\n",
    "        self.observation_space = Box(low=0, high=1, shape=(size, size, 3), dtype=np.float32)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        obs = Image.fromarray(obs[34:194, :160, :])  # crop the center square\n",
    "        obs = np.array(obs.resize((self.size, self.size), resample=Image.BILINEAR))\n",
    "        return obs.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also apply frame skip to increase performance ([Braylan et al., 2015](http://nn.cs.utexas.edu/downloads/papers/braylan.aaai15.pdf))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameSkip(gym.Wrapper):\n",
    "    def __init__(self, env, frame_skip):\n",
    "        super(FrameSkip, self).__init__(env)\n",
    "        self._frame_skip = frame_skip\n",
    "\n",
    "    def step(self, action):\n",
    "        total_reward = 0.0\n",
    "        for _ in range(self._frame_skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we have to ensure that the environment takes one hot actions, rather than scalars. This is simply because our controller takes one hot vectors as a part of its inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotAction(gym.ActionWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(OneHotAction, self).__init__(env)\n",
    "        n = env.action_space.n\n",
    "        self.action_space = Box(low=0, high=1, shape=(n,), dtype=np.float32)\n",
    "        \n",
    "    def action(self, action):\n",
    "        return np.argmax(action, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compile these wrappers together with `gym.make` to make a single `make_pong` function. Nothing important, just neat to have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pong():\n",
    "    env = gym.make('PongNoFrameskip-v4')\n",
    "    env = ProcessFrame(env, 64)\n",
    "    env = FrameSkip(env, 4)\n",
    "    env = OneHotAction(env)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at observations from our processed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAZV21kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAFGZYiE\n",
       "ADP//vbsvgU1/Z/QlxEsxdpKcD4qpICAdzTAAAADAAB4HShe6DhKq9DAABt2OHH/CRpgAE6HSswZ\n",
       "jQN7RtBN/aGqOZnivUJXdAF+0sqyWPr3bCY0eAPu1FZlZv6MQifnVtc4dGigFTGhxajWkUT8zVsZ\n",
       "I+kyfCBflB7DoA5q9nShFnyUKJqg9pkEKWVVQ28XZ/1kPXllbq6fWr28tXGA2mL6ADzrwvi07wqb\n",
       "iP8ENl7iqSAVxD4JYtvSjcT/cLNvcloqeAY99ZBqC8NydIqIZdte5pRyr4tJ087rZLEyMq5ETd02\n",
       "gdp5wKB2QmTioKlMkKjuRYmkaI6baXEZK9/rhKSRCrWD2vPQDhKj55RWq3po15Dnd/UZnm0kmPGN\n",
       "OP8Yt6RgJ5Q6UqjsdQz0WC4hGPGNXTf96aIB7ktuAAASAhIJs2EAAABaQZokbEM//p4QAI98WMQO\n",
       "ikuRCKYDIQqvo0A5C8FZ+kPDOXRDMOGRaTVTDz8WUGp8BRzdY+HZJnKXgFTHWF3+EyfSpIKZ6zOg\n",
       "+alMT/BR6I/K1YPpbhfL0SswAAAAKkGeQniE/wAmsVcTOZjWlDuvxg8AoUUmXSPRYzss2FPctl4L\n",
       "C+LoaupjuQAAABMBnmF0Qj8ALoS6NxsuiH/XRbFwAAAAJgGeY2pCPwAL8Tbq9B4x6cQA/R7F3t6C\n",
       "1cQzyeoT3zT7Afeg7WqBAAAAUUGaaEmoQWiZTAhn//6eEABJSMnIZodp/zGZD0J4H79IoK39QBVO\n",
       "7EblYzXHsKqTLcpnP5crbg7lrtpgRZy1vq1MxIKs3xkInCje+uKXbyXagQAAACNBnoZFESwn/wAT\n",
       "63WlHqd3GZk+N37u6IAcdR2VM2m2WtgCwQAAABkBnqV0Qj8AAvvxAZgMs0zDFEO0ygQUszu5AAAA\n",
       "NAGep2pCPwAX6YPOytflAaAAf1gBWRPzlEqhJU2Eu1NeCjR+o/ox2WdeUubCugDl9hS7qzAAAAAy\n",
       "QZqsSahBbJlMCGf//p4QAElOA/h15UWABXlsKgp3jiVeHrOzVed6MDRpQSE6IYCqj5gAAAAXQZ7K\n",
       "RRUsJ/8AJruDiMjdN8ofEd8RTvUAAAAmAZ7pdEI/AC5giDM/k8ekpZZ+ks87JFcBNjq5u0v6OxX2\n",
       "ev1VgXAAAAAYAZ7rakI/ABefu/+oXflLzq379RMqmX6QAAAAckGa8EmoQWyZTAhn//6eEABJvixN\n",
       "9XXRJYW3JgoEwF9go/tH2ABUO3pFWNOqbmGgHVAhFFe/QpSS/zAhP68NdVEY0VLH2U6q/OhN1MrY\n",
       "g32i/hSoCLmS0Dc9iu1e9AZYqxgEZRRE7s0iWcnbKIh22/pUgQAAAE9Bnw5FFSwn/wATS6aG59X8\n",
       "QCkgaBPsDq1s7tEhii3i5LK6GsbZh4zzP8dq5UIT5GQsMsD9fFwnW+kd04KRtgsO7FE3AeHUzzpq\n",
       "ThBQKaghAAAAMwGfLXRCPwAuiRBUT8ABQIt68H7eQ1Wzy/niwnDse6hmtcR9moA+cSrBVxWwkPko\n",
       "Ljf5VQAAADEBny9qQj8AF+JrTNEvPRG8Zn3di0iASMVXwWoLQAA47kQDSvQIf7Pl/KAJ4rpAKmrc\n",
       "AAAAfkGbM0moQWyZTAhf//6MsABKEaygPqtAATH9YBgOz0WSMs0eX1aqdGOAqnHjqMdU4Nm0ZFzr\n",
       "rCEASSepSpHbZdJDn38khb5wqJnQdMma3R8un9qpAoXfmXsJHGBJv1mFV1L8qu7uyNFaU7V7cH4G\n",
       "c6kV4eRkAqv4akO8qEbkgAAAAD5Bn1FFFSwn/wAT63Wm2s4gbW6pKr8RciEa9Xpdj4yeCD8ABAqy\n",
       "0RSr7mqP75SvV2mtSLWX+sELcLFxB6mEgQAAADkBn3JqQj8ALg8py8GfbqUZQwMw2+k8Kq/lnIQ8\n",
       "mDcAQyHS69DTyo+TNs3QbAs13mPylnfkwrzu0KQAAACRQZt1SahBbJlMFEwz//6eEACPfFjEDopL\n",
       "kQimA3QfKDuyQAsA/JsKvRATtJJtoF0VnbqsPwGqmHK5pI+XAYWsJjq4sEe1684oIj/+NfKVH3Bt\n",
       "++8OCK4xLe2khNidAJCTbLlxyFDWNok0j6/Dn6qgMQLnI0j5rvVTNsP6NxK21Y6WdXxbALzj6ciP\n",
       "Eg7AXMeN8AAAADwBn5RqQj8ALorJRlDinJH2UhV06WBn0HjGiOwlZER4n2/O+/LmVJwhwCAnsNCT\n",
       "Ox6Td6DpfQFKmgnTx3EAAAB+QZuYSeEKUmUwIX/+jLAAlA/2wMn/21RgSbVU8UWHHA8t0jeUiZ2P\n",
       "d6HXKeNKP2ysKpo7GG0lbJvRrF6VeoGDkF/FHy2sE5FtKrfpK6JtbVVAw6oX3gxUjmTjyw5TU8Bk\n",
       "4i/GVJERGcMsTZk+qJxBsq6r4i6DnIAo5g7T1rbgAAAAVEGftkU0TCf/ACfW60o9Tu4z2NeAUKKT\n",
       "LupaJOS76/lZWgQXOPWR5ggFsfQrJ0ZAFwSa8NC38OliHFuF3JG+nzdZ27obzKN/8dlMBrzjIK2h\n",
       "8SyKQQAAAEMBn9dqQj8AL9MHocjb3yv11CntmXBd0yKAxDYDfjXHtdPU8uq66Oj+d2ACKrM6Frt8\n",
       "4HLNEOFmr00pK6mtpBYyRkDBAAAAaUGb2UmoQWiZTAhn//6eEAEk2cP27HU/IUBwARcyyaCodOf+\n",
       "TAmQAFzsUgeyCqFmPaWF4e02TY+Are0p+4Jy3TXMPdFmL1VjBMvQ6Ppocus4MthVJOE/6meaxyXY\n",
       "wg1iQqcanmllYRH7rAAAAFZBm/1J4QpSZTAhf/6MsAEp+Jyc7PDpX5J69/rO/uAAg9f/xLfJofRx\n",
       "eQeR9zGNq2cEDxpMe/iizjCRAkKyqmfJ7lu9JgP4N6r4S495cCQ1EBL8kAfa9wAAAEVBnhtFNEwn\n",
       "/wBPrdrp71Ej9EB4Rh1TNscXA1dif8SdC++oAa4u5Rdrr73UIwkNsNemqKyny05H8v6fl2/M6XU7\n",
       "myLpZCAAAAA2AZ46dEI/AF05e/tPVFRtigbZyAANayUkkmMWWDJxhzI9r6vnYNGv5PBpxAi6pCqK\n",
       "xma4BziBAAAAJQGePGpCPwBfphxaKnZnl/4IzL2KThaVQA2Kn9x7/x/riYH2OC0AAABqQZo+SahB\n",
       "aJlMCGf//p4QAI98WMQOikuPpkuAF+hrD3CrdUYkkzyj6fqVIjcjFKj+5Jd++pC2EX5rp0csMK0H\n",
       "oaQhkWw3/qOp+Rqecdet2Waoz9BtlenW2x0ZSIX3nQKt4O6Opa+IofWXgAAAAJVBmkFJ4QpSZTAh\n",
       "n/6eEAAk3xYmDZcdGYvSyBjhOqIAcW4oHmbOsJhhcvwGvfXlIkRj+f/H869GDlC0OW/HJwDGEw3h\n",
       "Qzo16wUzEvFK8BRhV48wsIR7swjlI0pCRytgkQvjtm9kldV1xaNifCWCjyUgyihoejVPGg2FmfPW\n",
       "1IXCDv6almKFgaBNxECmS9L8VqiMxsOmYAAAAFJBnn9FNEwn/wAJ8yYgcehIBQgDaxtcwayy0/7P\n",
       "91PPlbV68eFfhrapFwsvISdHjf+d/DKjEHPBqPdJoyV9a+5JYp6DcIibkrlgVybtzdzJSJSBAAAA\n",
       "RQGegGpCPwAF+JrN4mYdSkKVHvUYhN2V5wBDn3yik2+rmiIlq4MxGs/fkyhrRXQFrdwyKY8XPltV\n",
       "k7HP09d55CRR5X1/gAAAAKJBmoRJqEFomUwIX//+jLAFD7y/AH0nY+UULNZGF1yD0oZ3ocwmTZyB\n",
       "IlMHyz9hckuqszvZxUDOXj7zfq8zFgX+ZkEa0YX0E4ryINuyB9hEsMAHU/gGDvESzDKfC2BW8LaF\n",
       "KxaBA8OP9VWzUoRF5+Ki7tggqxRKWt0SPiSzTSO45+XWtKKWF8wkNWXql1WSmlOB7iEgT5gINP9X\n",
       "mjqKKIK3AF0AAABaQZ6iRREsJ/8ACfW61JWvM8uVhAlzX8AG7djzSLlQWhVGa4bw1eFvJsEKyWHt\n",
       "bJhZCn+MjCb527VM6eScFkLHOwVMfORBf2SYCZFiW6dkcHILz9ku7Cb5MPhPAAAARgGew2pCPwGc\n",
       "3gEUvq0KiFR8YaaGkSsCQnFIAq1bD4APua9rejgiuwcQLJlTIUy9vpF715f6uHLZbeTzUL3Q9ekO\n",
       "0mLmy+EAAAB0QZrGSahBbJlMFEwz//6eEAT2rQW6gEGjAfaJgKxARrn1l8NKTnPVyIBYIHwR0uqF\n",
       "7mP8ju/6yIUwLq4rPqMLBfZP17cqe3E/H6c+E5xuOg9JJIiOXqYKqfjPXqhbfUnxihe4otjhkGi8\n",
       "MERlfsa00WiLlA0AAABBAZ7lakI/AZwp3K4jgZPSHA4HkqqATTGQ5l7VUNvBNHH4r/oi4lW5I1fe\n",
       "xyUJBQXS0znoOiY/yqrKUS4so1TBvGkAAABfQZroSeEKUmUwUsM//p4QBRV92Dz+I77fbdIjfzAC\n",
       "FPepfYNMv1Y80tF9AgzuMM5+XoI5trpCUPSqG/fhrmakztFQiFWHrSaUQzhiqaNbIgcsLh8jyy98\n",
       "gBrlie+L2CUAAABFAZ8HakI/ADdTJivVkvgByglc9n90dcU5bv2SUIwmjXM9w7f9SG7dve+nBICT\n",
       "9kFFJl0MozCzl87GCRuf4NIBDxvWcNtgAAAAnkGbC0nhDomUwIZ//p4QBkehCACUXOhqJ6rzJgvH\n",
       "nPFwJVvDMXxGFzwXGQ7UBp3lKTqPcs7T7rpt15O5aBgQVEX0qYtnrxTkoeNR8B4iGlS8CprJmtfz\n",
       "u8amqf3snRCw0gjBX74rSSmWOiypunyuFTRFFfMD3VkVQk38tV/rAerjLWkqju45IcJVboN3DIlb\n",
       "frMyF1Hv+BBRoeFZdoHJAAAAREGfKUUVPCf/ALXb/QvSt5Ic2ygA4EyxWDk0PoHwv/lyaUd1J7br\n",
       "Fz20uf4dfBw5aevP/fTwovRMHSCPXOeTB82imfxtAAAAdgGfSmpCPwHm3JBN3XqbISIArfUm/3BV\n",
       "295dUZiNqfuHJNgfQJSbLWTMDXH8sdBgutU4uvY7KO2+LBbP9SMv/Ulj9ifrT5GOCLtSO+HUtli4\n",
       "3yAddGJ/P9/hQvoSuHpdPGJaKBAfhTQ8KWGXVUbqumF/EfIX8DwAAACCQZtOSahBaJlMCGf//p4Q\n",
       "Bka//4I2+UAoHyLphlPOttqLWhYsNKD4wL4e3Ma+FsUB+M3+eZEQpf6eshAeA3leYQ3jeqzRJNXU\n",
       "2pY3Xlwb/3RxHE/2MsLXIXZ890Lv9MlmIc/cjoSVwGyZhpp/50jW0Mc3KnGfsmTjbzJD6iMUF80f\n",
       "8AAAAFJBn2xFESwn/wGano86UWSMe8OAImNBUD+qLqjcIk5SzlHzaqxos8qr2LaEcQRMONCB0dtA\n",
       "c/LizoPE1aUW7tKXqiEP6IFmdKPwDoQor8k7EXuhAAAAPAGfjWpCPwHmif0XkgAnWup5wgmL4VcG\n",
       "fayqH6bxd35OA5VrObp5ZThwFiDjpwl/NXrcEaVD86uHKNT/9QAAAFlBm5FJqEFsmUwIX//+jLAG\n",
       "X55sAeLbsqNSYtEova6pnltN3xpUuYnlOCdFhLn4UoWnlXjqzrLXfxbD0ozSdnbUtDyBovM8ic12\n",
       "qTD1vVEHWsMPicZfiJvl/QAAAEBBn69FFSwn/wGWG+YAR/4jyC2MTXptxLNV1CNN9VD5aURoYNqe\n",
       "28LupbJDokiF5C8Xsgd/4X4P5pqDgGlBKhPAAAAAQAGf0GpCPwHlVXA1UVROJAB3GcvuITapdMNh\n",
       "oDskLGCO9z+zwuSP33VnrvGOFYd5lvLsADwVIVr2w4csbWy0fVsAAABrQZvTSahBbJlMFEwv//6M\n",
       "sAZc4FM+ptb6/5gW03XDHcxp11vNv/FfgCsQgx0fyHqcZnp7XTjY1xWb9zQBU4ocMWE7CIOEOXq1\n",
       "HGFqf4RekATWNThHViH3+JFLZo4e0MAoXiQfp1Z6m8Ox5esAAABDAZ/yakI/AeYB5e++0ACEWUnH\n",
       "Dxpo/hZUgnFUh6NjUAS+InxGpg1yRUDpunFNI9EAs51ruMLWaHIS1eVh5OnVsap5bQAAAKVBm/VJ\n",
       "4QpSZTBSwv/+jLAGFDjaNvB9G9Fqkj55P69WggAG/G/G/WRuUmHjVEQ8dkEHOWd5GqzTn4zDF7YY\n",
       "YYmNF29olOK6ZgQgxgb8wGluPm/ZiFW3yFx1iDQpC8GR01WHcox+gQdeQRh4ZaJycY7LTgkNS+Ub\n",
       "ljdc6C4C53Y2w7Zm92DY5jTf076z6ToF8M19RcwmtSdgpD2TTs+G4naN1Whm2eAAAABeAZ4UakI/\n",
       "AHmElEHkDgh0mjoKnua2EPouIyt84ReShYqT90NWiw9ZakUkPDU+LIezdcFOTZS/du5FyBHnx9v8\n",
       "u4/nDEVDhb2zybkR66x1En1RdYQ2wmpaCVzljGU2UwAAAItBmhZJ4Q6JlMCF//6MsADBcJajuQg9\n",
       "UVTWrkLRYTLZfAq9eAHSB3usir0Fz7GtUWWpf5/+0F6ovFIDB31QHPFPWUIA0Hb/XjeWbOCAzLBt\n",
       "Oefa87cY4B1m33fDBsgFdBqO7CXknN5yV5yzGNQBnQlUQes7lMdWcQgUbyuSpLc9oXQS7zZX4o3A\n",
       "tQgYAAAAiEGaOEnhDyZTBRU8K//+OEABdfWFtXB0gIbKAT9zn8KDWa88Ucu/THiCbfOiYNMrfL8k\n",
       "uFBBSXfakORMqxe4A/OWe8H58KnXzWkqUlQO5vMGSzvAM1nirt2H41y6m3yGfAPlVe8pmj83hMe/\n",
       "Z/fzcFS7e6lBUKyqpZIjLEC2fivOmsmw6RHRAcEAAABTAZ5XakI/AB5qZ08C9GkKPGrcgPfKay/x\n",
       "8ABDpHN+ont8bftouuH7D49oUI3JRq2TqyXxDQtz0gftTzrdL9g/84sswvdlkyhzMGGAxAKwksjK\n",
       "Hu8AAACRQZpZSeEPJlMCFf/+OEAEVFTkABgZu8xuDllX6i3IH9EhklS78B4+mRgzbFtz8iC62U6A\n",
       "Fpeu6kAg4pq+Gh0DaI54DsIljzv7xrqQm/w6TAo6UJ84dwN6W2Wz/joGp5/F5gWXD2a+jjvGvRSH\n",
       "0+/SbJqTFWpXU6L3MR9OX/gpN0jJx2Te/BqLn3mmEQfI1GuHpgAAAF9BmnpJ4Q8mUwIX//6MsAJA\n",
       "RzbBXDoiwqGzGRk0/VtqOGO8Yyd+EsdAJnPhf0tknf4KxojYsErVlfzz06SgqskpZ02g641iIbhU\n",
       "hkOcFM497Cnijy0UakPoIxj/ziH7QQAAAFRBmptJ4Q8mUwIX//6MsAJAjgesoeygWuiACDdb6tZC\n",
       "o6/3CS4BXX0ipIh13I3Wsvp/OTwtmK90UZVhzVHdZ63mGLSMvocKSSYhm+02hN1TeyLXqw4AAABg\n",
       "QZq9SeEPJlMFETwr//44QAR75mpN7RKKsjXP4YdU9dYSp2wYDrvtnFuYfDRDy+ff7wJUBseqATPl\n",
       "UmHqk+3nfsqk7d1czPgw7ed4TGsKWzlrwMXFm9MzJnPTSzRMupfdAAAASgGe3GpCPwBfia0ArNQQ\n",
       "zu8AARF1tJriWr+1v5Z+58MGF3ynvYzMOGqztynx3lvuKLYLsTHv6HNgFLNmsFe9OBSWB8BgI0pc\n",
       "9uhBAAAATEGa30nhDyZTBTwj//3hABDT9ZjbNLSOqjBe6EWxPZrdrpSFKHq4AaQImqWvVqKoeXuR\n",
       "DWVxBqk5P5oryBqr/d2d3C3vDlQImQFjxnYAAAA0AZ7+akI/AF0Vastq2fq2arRB5ABxeIel8+KM\n",
       "FXbgSq+Sg1oM/Y6OIEUFkbdWgfeXmhVzTAAABeZtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPo\n",
       "AAAGQAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAFEHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAA\n",
       "AAEAAAAAAAAGQAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
       "AEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAABkAAAAIAAAEAAAAABIhtZGlh\n",
       "AAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAABAAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAA\n",
       "AAAAAAAAAFZpZGVvSGFuZGxlcgAAAAQzbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYA\n",
       "AAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAD83N0YmwAAACzc3RzZAAAAAAAAAABAAAAo2F2\n",
       "YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAEAAAD\n",
       "AUA8WLZYAQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAA\n",
       "AAEAAABAAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAAByGN0dHMAAAAAAAAANwAAAAEAAAIAAAAA\n",
       "AQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAAB\n",
       "AAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEA\n",
       "AAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAA\n",
       "AQAAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAgAAAAABAAAE\n",
       "AAAAAAIAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEA\n",
       "AAAAAQAABAAAAAACAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAAAwAA\n",
       "AAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAACAAAAAAEAAAMAAAAAAQAAAQAAAAADAAACAAAA\n",
       "AAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAABAAAAA\n",
       "AQAAARRzdHN6AAAAAAAAAAAAAABAAAAD/AAAAF4AAAAuAAAAFwAAACoAAABVAAAAJwAAAB0AAAA4\n",
       "AAAANgAAABsAAAAqAAAAHAAAAHYAAABTAAAANwAAADUAAACCAAAAQgAAAD0AAACVAAAAQAAAAIIA\n",
       "AABYAAAARwAAAG0AAABaAAAASQAAADoAAAApAAAAbgAAAJkAAABWAAAASQAAAKYAAABeAAAASgAA\n",
       "AHgAAABFAAAAYwAAAEkAAACiAAAASAAAAHoAAACGAAAAVgAAAEAAAABdAAAARAAAAEQAAABvAAAA\n",
       "RwAAAKkAAABiAAAAjwAAAIwAAABXAAAAlQAAAGMAAABYAAAAZAAAAE4AAABQAAAAOAAAABRzdGNv\n",
       "AAAAAAAAAAEAAAAsAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwA\n",
       "AAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_pong()\n",
    "fig = plt.figure()\n",
    "plt.axis('off')\n",
    "ims = []\n",
    "obs = env.reset()\n",
    "for _ in range(64):\n",
    "    action = torch.from_numpy(env.action_space.sample())\n",
    "    obs, _, _, _ = env.step(action)\n",
    "    ims.append([plt.imshow(obs, animated=True)])\n",
    "anim = anime.ArtistAnimation(fig, ims, interval=25, blit=True)\n",
    "plt.close()\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE (V) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $V$ model will have the same architecture as from the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)\n",
    "        self.fc_mean = nn.Linear(1024, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(1024, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x), inplace=True)\n",
    "        x = F.relu(self.conv2(x), inplace=True)\n",
    "        x = F.relu(self.conv3(x), inplace=True)\n",
    "        x = F.relu(self.conv4(x), inplace=True)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_mean(x), self.fc_logvar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 1024)\n",
    "        self.deconv2 = nn.ConvTranspose2d(1024, 128, 5, stride=2)\n",
    "        self.deconv3 = nn.ConvTranspose2d(128, 64, 5, stride=2)\n",
    "        self.deconv4 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
    "        self.deconv5 = nn.ConvTranspose2d(32, 3, 5, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = x.view(x.size(0), 1024, 1, 1)\n",
    "        x = F.relu(self.deconv2(x), inplace=True)\n",
    "        x = F.relu(self.deconv3(x), inplace=True)\n",
    "        x = F.relu(self.deconv4(x), inplace=True)\n",
    "        x = torch.sigmoid(self.deconv5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        if self.training:\n",
    "            return self.reparameterize(mu, logvar)\n",
    "        return mu\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(mu)\n",
    "        return eps.mul(sigma).add_(mu)\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_ = self.decoder(z)\n",
    "        return mu, logvar, z, x_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory (M) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the exciting part! Our agent's ability to predict the future based on its action is, in fact, the essence of a world model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureDensityLSTM(nn.Module):\n",
    "    def __init__(self, latent_dim, hid_dim, act_dim, num_mixtures=5):\n",
    "        super(MixtureDensityLSTM, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.lstm = nn.LSTM(latent_dim + act_dim, hid_dim)\n",
    "        # mixture density network\n",
    "        self.num_mixtures = num_mixtures\n",
    "        self.fc_pi = nn.Linear(hid_dim, num_mixtures * self.latent_dim)\n",
    "        self.fc_mean = nn.Linear(hid_dim, num_mixtures * self.latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hid_dim, num_mixtures * self.latent_dim)\n",
    "\n",
    "    def init_state(self):\n",
    "        return (torch.zeros(1, 1, self.hid_dim), torch.zeros(1, 1, self.hid_dim))\n",
    "\n",
    "    def mixture_coef(self, x):\n",
    "        pi = F.softmax(self.fc_pi(x).view(x.size(0), -1, self.num_mixtures, self.latent_dim), dim=2)\n",
    "        mean = self.fc_mean(x).view(x.size(0), -1, self.num_mixtures, self.latent_dim)\n",
    "        logvar = self.fc_logvar(x).view(x.size(0), -1, self.num_mixtures, self.latent_dim)\n",
    "        return pi, mean, logvar\n",
    "\n",
    "    def sample(self, pi, mean, logvar):\n",
    "        stdev = torch.exp(0.5 * logvar)\n",
    "        return torch.sum(pi * torch.normal(mean, stdev), dim=2)\n",
    "\n",
    "    def forward(self, z, a, h, c):\n",
    "        z = torch.cat([z, a], dim=-1)\n",
    "        z, (h, c) = self.lstm(z, (h, c))\n",
    "        return self.mixture_coef(z), (h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controller (C) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, Ha and Schmidhuber used CMA-ES to evolve the controller, but that's not a requirement. Since our problem environment is simple enough, we'll use the single threaded **A2C** (Advantage Actor-Critic) algorithm to train our controller.\n",
    "\n",
    "Now that we decided to use an Actor-Critic agent, we may ask a question: since different components of the agent is trained asynchronously (i.e., first $V$ and/or $M$, then the $C$), when should the critic network be trained? When training the world model, or the controller? We'll try that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, act_dim):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.actor = nn.Linear(state_dim, act_dim)\n",
    "        self.critic = nn.Linear(state_dim, 1)\n",
    "    \n",
    "    def act(self, x):\n",
    "        pi = F.softmax(self.actor(x), dim=-1)\n",
    "        dist = distributions.OneHotCategorical(pi)\n",
    "        return dist.sample()\n",
    "    \n",
    "    def value(self, x):\n",
    "        return self.critic(x).detach()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pi = F.softmax(self.actor(x), dim=-1)\n",
    "        dist = distributions.OneHotCategorical(pi)\n",
    "        action = dist.sample()\n",
    "        logpi = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        return action, logpi, entropy, self.value(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can put together an agent! Pay special attention to how the agent makes an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, vision, memory, controller, device=None):\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.device = device\n",
    "        self.vision = vision.to(self.device)\n",
    "        self.memory = memory.to(self.device)\n",
    "        self.controller = controller.to(self.device)\n",
    "        h, c = self.memory.init_state()\n",
    "        self._h = h.to(self.device)\n",
    "        self._c = c.to(self.device)\n",
    "        \n",
    "    def act(self, x):\n",
    "        x = torch.from_numpy(x.transpose(2, 0, 1))\n",
    "        x = x.unsqueeze(0).to(self.device)  # add batch dimension\n",
    "        z = self.vision.encode(x).unsqueeze(0)  # add time dimension\n",
    "        s = torch.cat([z, self._h, self._c], dim=-1)\n",
    "        a = self.controller.act(s)\n",
    "        _, (h, c) = self.memory(z, a, self._h, self._c)\n",
    "        self._h = h.detach()\n",
    "        self._c = c.detach()\n",
    "        # numpy one hot vector\n",
    "        return a.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 16\n",
    "hid_dim = 32\n",
    "act_dim = env.action_space.shape[0]\n",
    "state_dim = latent_dim + hid_dim * 2\n",
    "\n",
    "vision = VAE(latent_dim)\n",
    "memory = MixtureDensityLSTM(latent_dim, hid_dim, act_dim)\n",
    "controller = ActorCritic(state_dim, act_dim)\n",
    "\n",
    "agent = Agent(vision, memory, controller)\n",
    "print(f\"device = {agent.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the environment, let's see if our newly born agent can interact with the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"432\" height=\"288\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAVo21kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTUyIHIyODU0IGU5YTU5MDMgLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9OSBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAFDZYiE\n",
       "ADP//vbsvgU1/Z/QlxEsxdpKcD4qpICAdzTAAAADAAB4HShe6DhKq9DAABt2OHH/CRpgAE6HSswZ\n",
       "jQN7RtBN/aGqOZnivUJXdAF+0sqyWPr3bCY0eAPu1FZlZv6MQifnVtc4dGigFTGhxajWkUT8zVsZ\n",
       "I+kyfCBflB7DoA5q9nShFnyUKJqg9pkEKWVVQ28XZ/1kPXllbq6fWr28tXGA2m3hvax7WWd+0kvW\n",
       "5AkQggTjp1foV7n+nTK3KHFoAnzkWygs43g2iKjWmq218iDCQriIkuNQMvvz4ykH4LhmuzYPQH2R\n",
       "Jf7pf7DqAmDzoLOycx3Vz7CzwTHa1KUmUYJFDGoXcwJHhukPMv2MtILpda8Le6Wp5FfB1/G1aP8Y\n",
       "t6RgNBj1bSZLCyPbcFbVU7LtE6RbIzwYF6u3AAAuhNH2Y8EAAAARQZokbEM//p4QAI98WMFgN6AA\n",
       "AAATQZ5CeIT/ACaxThXlsjxPf9eU0QAAABcBnmF0Qj8ALf/zVxWoUtt9jibGPL96KAAAAB4BnmNq\n",
       "Qj8AF03AIF+AAiK/srSvEd7b93m60KySmxcAAABWQZpoSahBaJlMCGf//p4QASUjJyAdp0pIwvhl\n",
       "ZiHA2/FEElLIop29LmcTXUHbq7XnvSyfi6M5eNiziMCFmdzVAvb97n/qUGGjJQTjfxj3oxCLYeYA\n",
       "+ScAAAAcQZ6GRREsJ/8AT63WmqfO0wxS27nnpAAPBVLFgQAAABsBnqV0Qj8AL9cXb7Bi4FqtqC7S\n",
       "AGx2tA0u3j8AAAAVAZ6nakI/AF+mDzoZCAP/NPgnuDZgAAAAWkGarEmoQWyZTAhn//6eEARwl9Eg\n",
       "A+noN2+qmx8kKEm9F3k1Pu/74wsPwGqeeHSYLeccwJq9A2+dTyNhELWEgj9VSc7NpVFDk2DQ2Bip\n",
       "dZTwJzQJcNAF+kjFgAAAACRBnspFFSwn/wE12+7PMaX7t/YICzXFCCIM2pK3brOkWiyBDFkAAAAW\n",
       "AZ7pdEI/AL9wnv5VoUUF2mgZf0kMWAAAABUBnutqQj8BdMUnANlvVvq+/H1gcsAAAACIQZrwSahB\n",
       "bJlMCGf//p4QBJf8kwALAKRfYAHpKRC2XNdDpT/96F4aFR4Csxg/Tz9eTvzuDA5uupLdfTWc4tA6\n",
       "kP2+MSOW6t1/8EztKTnUHyVVm8gD14a6qIxkze/sp1V+O1jBga/WOUuWGr4BxijYqf83C6nWu9+T\n",
       "DOnKANFu7OJzagpi6osSmQAAAE9Bnw5FFSwn/wCZjH6HBeECNaPUTVl5AKSBoE+wOrQQp0SGKLbO\n",
       "zLU6GE6BzYW1cqEJ8jIWGWB+vi4TrfSO6cFI2wWHdihgDhIGc9Y4ejehAAAAHgGfLXRCPwF0izOo\n",
       "V+DFHkRTde9H68+DGubmOYvqtwAAAC8Bny9qQj8Aum30/AAITF3ftZuEkJDxUIALk6G3J4uRANK9\n",
       "Ah/stkB8iQB3YMBVbgAAAGBBmzNJqEFsmUwIZ//+nhAEdYOAvaUANj7UIG1y0vk+VD4PYRCwARZH\n",
       "wopIE2NoBBp0VD3/6Iav+FYPmj+9uz+bZSfZMW8Sayxu7oaampXD/D9w0oclOAyzYbPLd8cwJ2gA\n",
       "AAA/QZ9RRRUsJ/8Cai793+87YHoU0N+X5wHbjxz7J04Ho9/AAQKstEUq+5qj++Ur1dprUi19ww2C\n",
       "Kt5mLWBD7QZTAAAAMQGfcmpCPwADdFTM49W/Ec/S08RzETffYAN47S69DTyo+TNs3wIaPNIye2Hv\n",
       "oV6o50wAAABfQZt2SahBbJlMCF///oywAAYL0cDo0uvoISxpOfN+wCDnkBWZXTD4R1+xJKGHblYj\n",
       "K2psDVfe4+jXxaKTVYphcuRVgU9sUThRUk4+we66Cz7qLtQ8Xogw9qetsccbO4AAAAA+QZ+URRUs\n",
       "J/8Cai8Qz9BadGGNkARovX10kv2xjpXaqmC4TrpHZ5Z8alsIX/3Lqm7F7YOd6OoPsCr2BYghSpkA\n",
       "AAA3AZ+1akI/AAHl/psiUu+O9AA4yzOZKzTFLJ2ZsP4KESJWqYfbZ6hgIZXPgJpvzpZcU9qOprdk\n",
       "EAAAAEFBm7hJqEFsmUwUTC///oywAAMFwlqO49mK44FINkTurdP6jhagBIo1WyVd8rL6OhquI0QZ\n",
       "AucbNoWiQ5Bp6mrTgQAAADoBn9dqQj8C6BQQ0yg+wd38Gle23120EqyqJqhu6Oj9qQAEVWZ0LXb5\n",
       "wOWaIcLNXppSaoChDbIdJPBhAAAARkGb2UnhClJlMCGf/p4QAAF9sAzTZyANRNSOihMAwf9CGhBy\n",
       "2nwuUADRYSLOhZc2oBSAs6YH2z/q42s76DVBwb1QX5kW04AAAABmQZv9SeEOiZTAhf/+jLAEfylu\n",
       "DsMQgBGXNNgDds9G4QnqVMNLTSajBE2Fc9jSKFqnhPkZJitK7lxIWo/Y8WUxaZSmvWSY9/pvuPbK\n",
       "BM+WOYP7jMcrul0wGR2SHwnY73rI6JjbXk3/AAAAPUGeG0URPCf/Amn5nk7FOA5L7oRQYEEZFul+\n",
       "AAhI1yItpAXeoRhIbYbwVJgvAlKGfRSutZj34UStYAz3BIAAAAAyAZ46dEI/AL79AGt/AIfcRfyv\n",
       "JV1XxYM/dFADgvFAVWZEW06usrns50RjqkV5B5WKWf0AAAAgAZ48akI/AXRVIca+TepvYTfpuRjR\n",
       "ksACC2h0zQdeJqMAAABLQZo+SahBaJlMCGf//p4QBHWBhCwAllb/fjRbec1vtsBdJkgSDrzyEz7s\n",
       "XZZLlDHw6gX89Zow0HAIvV03tPFxzU3+tjwUIPJMNtNgAAAAZUGaQUnhClJlMCGf/p4QBHWDWg0n\n",
       "onyQ4A8AmU4ZgnXIy7C9oZJZrTzNnUyKIcYzZhCP9sSd5HTwOSbjmjxFvvCRpzoswikUE9TGUkgH\n",
       "CjHhr0qpnMvsCO9ZypLJR9EhHYAV7H2gAAAAPEGef0U0TCf/Amn5nIeDkM92OoUdSnj6uOoUa8Zt\n",
       "NGAaih/biAImOcUZwQz0FRs0lxYNiKKhWA3hhJA8wQAAAEYBnoBqQj8BdMUnYI2dGirs+7Qrgvr5\n",
       "MANtPG4ll4he5J7VcGYdVqNbq7VnXoCwVUWU51Vr8/oJp6rddERSXJz7EYZqIn7AAAAAf0GahEmo\n",
       "QWiZTAhf//6MsAUPvL8AfSdj5RQs1kcXVjxks8f5FJDqShqSFyxLX85/LP2Jyn1EAx9/LqT9+FZW\n",
       "aM2G0j6p/I3l7NXCDl9FKlnChBYO3vcKYcWUgUdKEztP4qr0VugN+V5vzQYoYk3Q+we4hINPwKzT\n",
       "RhJR97dRRkkAAABQQZ6iRREsJ/8Cai71i4VOxQlot03BST8dLXh6AApDgaRgpZxaSHTV0an5DJUr\n",
       "9wXmzpH+KfN8IlK/HE3ZzVU4cnAN3C3zl3hiPI3aupD6Y4AAAAA9AZ7DakI/AZzeDz4n4/SAbjpf\n",
       "sAKZOQEoAjUqz4APua9rehtEEi4gWTKmQplbqR7OGiYfWNe+8TGahq1lgQAAAGVBmsZJqEFsmUwU\n",
       "TDP//p4QD77HgVm0S3UAg0YD7RMBWIDbtGU/hpP856uRALBA+COl1QvUwHedyJ5s38fysbjroUI4\n",
       "w0Jg1u5gzYhzjcZyW5tM7PXqhbfUnxkzkIBOIjbbtnyPJQAAADUBnuVqQj8BnCncriN5ZPJIKz/X\n",
       "BAEJKyNAknDPyXESsjnh197HJSh/5lWwQQpr86vOGx1LFQAAAFlBmuhJ4QpSZTBSwz/+nhAGR6EI\n",
       "AJRc6GonqvMmCwhcwQSjmr19t0iN8NH3qX2DTL9WPNLRfQIM7jDJAmUu1OA0Pcz/gYx0iNQIu6Rn\n",
       "mmPTyy9H/LoW8xHE4QAAADkBnwdqQj8B5oj3NKSC8RAwAdAJXPZ/dHXFOWuLLjYFIgQTdw7f9SG7\n",
       "dve+nBIB9MidbVYzsmpWvB4AAABiQZsLSeEOiZTAhn/+nhAGRr//gjb5QCgfIumF486nP/jewHNz\n",
       "ozKn7d5DtQGneUpOo9yztPuum3Xk42Rl/Q48f3iQVt5nQyEWHCChkiruO4ZCPiChRdbVPgb0RYPD\n",
       "5K0PbJwAAAA2QZ8pRRU8J/8Bmr3t9SOK/gENHef2AIdygqJxRB9Ba1/8uTSjupM+diPediAzR7CT\n",
       "KeUAHzatAAAAOQGfSmpCPwHmiRwSk2u4oSACPdSb/cFXb4vpVHw4T9w5JsD6BKTZayZga4/ljoMF\n",
       "1unta9jsuWREvAAAAF1Bm05JqEFomUwIZ//+nhAGRr//gjb5QF2eQxLsU86nSotaE/kaUHxIXxUi\n",
       "b0h8LYoD8Z9Eu430Kx9HUqRQX6ro+WAVfGZovzoMfUO3DeGkeQ1qu/aQnS8lVuz5o9oAAABNQZ9s\n",
       "RREsJ/8Blhuasqx+EA2b8AIyNBUD+qLqjcIk5Sqe5zcGxos8qr26YMcLl9RCmJDm2gPAZtQHp4eT\n",
       "5UmY+boXnT6+M3EwJmfKFtEAAAAwAZ+NakI/AeaJ/ReSACda6nnCCYvhVwZ9rKofpvF3fk4DlWs5\n",
       "unllY0MwBMDrmJbRAAAAR0GbkkmoQWyZTAhf//6MsAZQWFWT/yanF63MqewBt1n/kS/0SXViiiTl\n",
       "yRSByhhhhRpI5r7E4KKJtObXSog+v2nhrBkT3UIvAAAASkGfsEUVLCf/AZohPwAt4VE/ALr9w1L/\n",
       "Ld9QpSMHMUOm3T7J3fCdzxM/nhPlryJIwapZKvoGX18NiMMgkFG0V5nhzUywMu/mFnNqAAAAKAGf\n",
       "z3RCPwNcyVVrAKSxkAE0y2xbL4teiJfZfG/690XwvT8MpZarKf4AAAA9AZ/RakI/A1s1aNqqG5YM\n",
       "djsk9+96AAhZvVGQbkvR88cqhY3P2Ht7/c8aDhrTotbgyosRiVh+NPXBDljwgQAAAEZBm9NJqEFs\n",
       "mUwIX//+jLADBfmqmDzBJIamy7AJzPWxCjW/8riiXkwJFDkGdtX4XFoz1EO70Sthh/oMJk2/Xz8C\n",
       "FppWsQZUAAAAfEGb9UnhClJlMFFSwv/+jLAEhYTD+bYAMtOsJWubKxjfg1ivpE/s0VUa3Nsm9Jm1\n",
       "FYH7FJG65/DUJIXLCu3lrALsxBBCPqAKt7Yg4WueO7wLUazfkuKPmNfwUW+djZeBlSVvnjE/KnIK\n",
       "7t++inMrR/K1TLprMMr/HDISI+AAAABDAZ4UakI/AXTFJfFGJD2HLCNFN+y3fJyiGC+yf+7K235V\n",
       "gSuCWgwP3Q1aLD1lqRCP8NT3QirOhu+SuRMy+/PubCQB3QAAAHxBmhZJ4Q6JlMCF//6MsASn5rdv\n",
       "0FYgXyjp2oAAWujnaoZDCZhIjfp+sSw33ROKYDVPXPcDrktOFVIcBV5xS2C9tN/HBN6T3wLM66DN\n",
       "Ua10mdFfnS3bqwuPeAPVN199h/nBjVRkKV/BsE6/s3BP/Mn0uHkeN1WjMGAAyNpOAAAAiUGaOEnh\n",
       "DyZTBRU8L//+jLACQKZT1pHi3YXlVwePyRCcLG+v40QqbjUcipnCeDkA0AcQASUMM4+wEAL2eDoN\n",
       "11sQMzjnEnNAAlmpze0YGu3b7dwprVNhweAzrUSMV7V6GSoY1RmtuEmvj7h22A0+nsMnsHvS4rcL\n",
       "hh+CTxIaBgySvXNID6C96GVBAAAASwGeV2pCPwC8//wsMQ8BSqgKKMCXkCbzG+O/8wA2Y4g4EmTZ\n",
       "e5JApDi0AQiMBEAqs4gCh5JYDxnvZWfF382b+nerND82ERBcRyFpIQAAAFZBmlpJ4Q8mUwU8L//+\n",
       "jLABIDhOixrK7c6jp/ZMRI+SK1GAESSAnJQl7LhEKy89y4D2wMD95dvLGdUCBrvQ6BaQGg2NnYdh\n",
       "TiPVSPN1J95puT8xb5aRbAAAAFABnnlqQj8AXTFJyt0+VjZQA1l2DwEMxZ9s7uYcDLK0XTV1U8Uv\n",
       "ItJKvVz3ND01xHB9I2G5vSCKnIcUh12nO9d9XeGun6Hc7U/wF0IF4Hl7gQAAADxBmntJ4Q8mUwIX\n",
       "//6MsAAYLhLUzocAVzh0rrNDPzlDDPQyf58AAjLOrpjL51CkkpECVjMsJdU3si3Y/ZgAAABnQZqd\n",
       "SeEPJlMFETwr//44QAjokbiAYNrCwqvUfm8EL7f2RfbQXdEb+Os5GbhQHr1frmo354rihsN3pPnx\n",
       "Ee3YdBkhBf8JRZFC/6rbWb8xSePMZDR23JQ8AsyK9yko14rLccdi5/WKnwAAAEQBnrxqQj8AvP/9\n",
       "jouRY4oYgCCs0iiC1qMz4usUHGwYcl20G+7/X/2BeycZ58Hb6etOuag6iQwv40+iSAf18e2ldHNc\n",
       "wQAAAGJBmr9J4Q8mUwU8I//94QBDdXTRxnqVUABOovgDio4JLdK1VGeow6NsdGRDyheDIILXYgMr\n",
       "rMVexUF9WULKW6JRyN496VANupRE3Vs0tbHjf/kqVXz2VxcVHvGJBgMZY8NwwAAAADUBnt5qQj8B\n",
       "dFWrLatjIOL6QkIRgAClVlWolA0cp26YubkpaaDP2OjiBFBZGy8kPvWuOER0gAAABf5tb292AAAA\n",
       "bG12aGQAAAAAAAAAAAAAAAAAAAPoAAAGQAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAA\n",
       "AAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAFKHRyYWsA\n",
       "AABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAGQAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAA\n",
       "AAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAA\n",
       "AQAABkAAAAIAAAEAAAAABKBtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAABAAFXEAAAAAAAt\n",
       "aGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAARLbWluZgAAABR2bWhk\n",
       "AAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAEC3N0YmwA\n",
       "AACzc3RzZAAAAAAAAAABAAAAo2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABI\n",
       "AAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkABX/\n",
       "4QAYZ2QAFazZQbCWhAAAAwAEAAADAUA8WLZYAQAGaOvjyyLAAAAAHHV1aWRraEDyXyRPxbo5pRvP\n",
       "AyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAABAAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAAB4GN0\n",
       "dHMAAAAAAAAAOgAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAF\n",
       "AAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEA\n",
       "AAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABAAA\n",
       "AAACAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAA\n",
       "AAEAAAEAAAAAAQAAAgAAAAABAAAEAAAAAAIAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAMAAAAA\n",
       "AQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAQAAAAAAgAAAQAAAAAB\n",
       "AAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEA\n",
       "AAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAACAAAAAAEAAAMAAAAAAQAA\n",
       "AQAAAAABAAADAAAAAAEAAAEAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAABAAAAAAQAAARRzdHN6AAAA\n",
       "AAAAAAAAAABAAAAD+QAAABUAAAAXAAAAGwAAACIAAABaAAAAIAAAAB8AAAAZAAAAXgAAACgAAAAa\n",
       "AAAAGQAAAIwAAABTAAAAIgAAADMAAABkAAAAQwAAADUAAABjAAAAQgAAADsAAABFAAAAPgAAAEoA\n",
       "AABqAAAAQQAAADYAAAAkAAAATwAAAGkAAABAAAAASgAAAIMAAABUAAAAQQAAAGkAAAA5AAAAXQAA\n",
       "AD0AAABmAAAAOgAAAD0AAABhAAAAUQAAADQAAABLAAAATgAAACwAAABBAAAASgAAAIAAAABHAAAA\n",
       "gAAAAI0AAABPAAAAWgAAAFQAAABAAAAAawAAAEgAAABmAAAAOQAAABRzdGNvAAAAAAAAAAEAAAAs\n",
       "AAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAt\n",
       "aWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1Ny44My4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_pong()\n",
    "fig = plt.figure()\n",
    "plt.axis('off')\n",
    "ims = []\n",
    "obs = env.reset()\n",
    "for _ in range(64):\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    ims.append([plt.imshow(obs, animated=True)])\n",
    "anim = anime.ArtistAnimation(fig, ims, interval=25, blit=True)\n",
    "plt.close()\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we can move on to data collection then."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we let the agent collect the environment data to train its world model. Since we're only interested in transition data ($s_t, a_t, s_{t+1}, a_{t+1}, ...$),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ['action', 'obs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: as you can see below, our `TransitionBuffer.reset` takes the first observation, returned by `env.reset()`. This means that each time a transition $\\tau_t$ is pushed into the buffer, `transition.obs` is not $o_t$ but $o_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionBuffer(data.Dataset):\n",
    "    def __init__(self, env, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.obs = np.zeros((self.capacity+1, *env.observation_space.shape))\n",
    "        self.action = np.zeros((self.capacity, *env.action_space.shape))\n",
    "        self._t = 0\n",
    "\n",
    "    @property\n",
    "    def full(self):\n",
    "        return self._t == self.capacity\n",
    "\n",
    "    def reset(self, obs):\n",
    "        self.obs.fill(0)\n",
    "        self.action.fill(0)\n",
    "        self._t = 0\n",
    "        self.obs[self._t] = obs\n",
    "\n",
    "    def push(self, transition):\n",
    "        assert not self.full\n",
    "        self.obs[self._t+1] = transition.obs\n",
    "        self.action[self._t] = transition.action\n",
    "        self._t += 1\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.obs[i], self.action[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObservationSampler(data.Sampler):\n",
    "    def __init__(self, data_source, batch_size):\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(len(self.data_source))\n",
    "        for i in range(0, len(indices), self.batch_size):\n",
    "            batch = []\n",
    "            for j in indices[i:i+self.batch_size]:\n",
    "                batch.append(self.data_source[j][0])\n",
    "            batch = np.stack(batch)\n",
    "            yield torch.from_numpy(batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        num_data_points = len(self.data_source)\n",
    "        last = int(num_data_points % self.batch_size > 0)\n",
    "        return num_data_points // self.batch_size + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = TransitionBuffer(env, 10000)\n",
    "sampler = ObservationSampler(buffer, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(env, agent, buffer):\n",
    "    obs = env.reset()\n",
    "    buffer.reset(obs)\n",
    "    while not buffer.full:\n",
    "        with torch.no_grad():\n",
    "            action = agent.act(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        buffer.push(Transition(action=action, obs=obs))\n",
    "        if done:\n",
    "            obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore(env, agent, buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
