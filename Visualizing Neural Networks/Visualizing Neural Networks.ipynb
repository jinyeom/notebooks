{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Neural Networks\n",
    "**Jin Yeom**  \n",
    "jin.yeom@hudl.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision.utils import make_grid\n",
    "from torchsummary import summary\n",
    "from visdom import Visdom\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from logbook import LogBook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 1.1.0\n",
      "Torchvision Version: 0.2.2\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization, create a `Visdom` object with the correct server DNS and port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visdom hosted at http://localhost:8097/env/CIFAR-10_VAE\n"
     ]
    }
   ],
   "source": [
    "server = 'http://localhost'\n",
    "port = 8097\n",
    "env = 'CIFAR-10_VAE'\n",
    "viz = Visdom(port=port, server=server, env=env)\n",
    "print(f\"Visdom hosted at {server}:{port}/env/{env}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def transform(img):\n",
    "    if np.random.random() < 0.5:\n",
    "        img = TF.hflip(img)\n",
    "    img = TF.to_tensor(img)\n",
    "    return img\n",
    "\n",
    "cifar10_train = CIFAR10(\n",
    "    'datasets/CIFAR-10', \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True)\n",
    "train_loader = DataLoader(\n",
    "    cifar10_train, \n",
    "    batch_size=16, \n",
    "    shuffle=True, \n",
    "    num_workers=4)\n",
    "\n",
    "cifar10_test = CIFAR10(\n",
    "    'datasets/CIFAR-10', \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    download=True)\n",
    "test_loader = DataLoader(\n",
    "    cifar10_test, \n",
    "    batch_size=16, \n",
    "    shuffle=False, \n",
    "    num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some images. The cell below should take a batch of training samples and project it on Visdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_375b0a404d32ca'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = iter(train_loader).next()\n",
    "sample = make_grid(images, nrow=4)\n",
    "viz.image(sample, opts=dict(\n",
    "    title='CIFAR-10 sample',\n",
    "    width=400, \n",
    "    height=400\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to train a **variational autoencoder (VAE)** for CIFAR-10, as we focus on visualizing how loss values change and how features in convolution layers evolve as training proceeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 4, stride=2)\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 4, stride=2)\n",
    "        self.norm4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 4, stride=2)\n",
    "        self.norm6 = nn.BatchNorm2d(128)\n",
    "        self.fc7 = nn.Linear(512, latent_dim)\n",
    "        self.fc8 = nn.Linear(512, latent_dim)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.norm2(self.conv1(x)), inplace=True)\n",
    "        x = F.relu(self.norm4(self.conv3(x)), inplace=True)\n",
    "        x = F.relu(self.norm6(self.conv5(x)), inplace=True)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc7(x), self.fc8(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 15, 15]           1,568\n",
      "       BatchNorm2d-2           [-1, 32, 15, 15]              64\n",
      "            Conv2d-3             [-1, 64, 6, 6]          32,832\n",
      "       BatchNorm2d-4             [-1, 64, 6, 6]             128\n",
      "            Conv2d-5            [-1, 128, 2, 2]         131,200\n",
      "       BatchNorm2d-6            [-1, 128, 2, 2]             256\n",
      "            Linear-7                   [-1, 16]           8,208\n",
      "            Linear-8                   [-1, 16]           8,208\n",
      "================================================================\n",
      "Total params: 182,464\n",
      "Trainable params: 182,464\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 0.70\n",
      "Estimated Total Size (MB): 0.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(Encoder(16).to(device), (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 64, 5, stride=2)\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "        self.deconv4 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
    "        self.norm5 = nn.BatchNorm2d(32)\n",
    "        self.deconv6 = nn.ConvTranspose2d(32, 3, 6, stride=2)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = x.view(x.size(0), 512, 1, 1)\n",
    "        x = F.relu(self.norm3(self.deconv2(x)), inplace=True)\n",
    "        x = F.relu(self.norm5(self.deconv4(x)), inplace=True)\n",
    "        return torch.sigmoid(self.deconv6(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]           8,704\n",
      "   ConvTranspose2d-2             [-1, 64, 5, 5]         819,264\n",
      "       BatchNorm2d-3             [-1, 64, 5, 5]             128\n",
      "   ConvTranspose2d-4           [-1, 32, 14, 14]          73,760\n",
      "       BatchNorm2d-5           [-1, 32, 14, 14]              64\n",
      "   ConvTranspose2d-6            [-1, 3, 32, 32]           3,459\n",
      "================================================================\n",
      "Total params: 905,379\n",
      "Trainable params: 905,379\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.15\n",
      "Params size (MB): 3.45\n",
      "Estimated Total Size (MB): 3.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(Decoder(16).to(device), (16,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        if self.training:\n",
    "            return self.reparameterize(mean, logvar)\n",
    "        return mean\n",
    "      \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        stdev = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(mean)\n",
    "        return eps.mul(stdev).add_(mean)\n",
    "  \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return mean, logvar, z, recon_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(16).to(device)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if we can add model summary to Visdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_375b0a41cad768'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since Visdom.text uses HTML, we must\n",
    "# preprocess the text a little bit...\n",
    "model_str = str(model).replace('\\n', '<br>')\n",
    "model_str = model_str.replace(' ', '&nbsp')\n",
    "viz.text(model_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(recon_x, x):\n",
    "    \"\"\"Mean squared error\"\"\"\n",
    "    mse = (recon_x - x) ** 2\n",
    "    mse = torch.sum(mse.view(mse.size(0), -1), dim=1)\n",
    "    return torch.mean(mse, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kld(mean, logvar):\n",
    "    \"\"\"KL-divergence\"\"\"\n",
    "    kld = -0.5 * (1 + logvar - mean.pow(2) - logvar.exp())\n",
    "    kld = torch.mean(kld, dim=1)\n",
    "    return torch.mean(kld, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(test_loader, model):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    for x, _ in test_loader:\n",
    "        x = x.to(device)\n",
    "        mean, logvar, z, recon_x = model(x)\n",
    "        recon_loss = mse(recon_x, x)\n",
    "        latent_loss = kld(mean, logvar)\n",
    "        loss = recon_loss + latent_loss\n",
    "        total_loss += loss.item()\n",
    "    model.train()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_encoder_conv1(model):\n",
    "    conv1_w = model.encoder.conv1.weight.detach().cpu()\n",
    "    return make_grid(conv1_w, nrow=4, normalize=True)\n",
    "\n",
    "def vis_encoder_conv3(model):\n",
    "    conv3_w = model.encoder.conv3.weight.detach().cpu()\n",
    "    out_channels = conv3_w.size(0)\n",
    "    in_channels = conv3_w.size(1)\n",
    "    conv3_w = conv3_w.view(out_channels * in_channels, 1, 4, 4)\n",
    "    return make_grid(conv3_w, nrow=out_channels, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1a7e5825944aed917195b7ed816ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271d002176c34f5d9976bbeee2be82e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = LogBook('i', 'mse', 'kld', 'loss')\n",
    "valid_losses = []\n",
    "\n",
    "# NOTE: these windows can potentially be \n",
    "# wrapped in a `Visualizer` wrapper class\n",
    "mse_win = None\n",
    "kld_win = None\n",
    "loss_win = None\n",
    "conv1_win = None\n",
    "conv3_win = None\n",
    "valid_win = None\n",
    "\n",
    "global_iter = 0\n",
    "for ep in tqdm(range(20)):\n",
    "    for x, _ in tqdm(train_loader, leave=False):\n",
    "        x = x.to(device)\n",
    "        mean, logvar, z, recon_x = model(x)\n",
    "        recon_loss = mse(recon_x, x)\n",
    "        latent_loss = kld(mean, logvar)\n",
    "        loss = recon_loss + latent_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # log training progress\n",
    "        if global_iter % 50 == 0:\n",
    "            log.record(\n",
    "                global_iter, \n",
    "                recon_loss.item(), \n",
    "                latent_loss.item(),\n",
    "                loss.item())\n",
    "\n",
    "        # update plot\n",
    "        if global_iter > 0 and global_iter % 100 == 0:\n",
    "            mse_win = viz.line(X=log['i'], Y=log['mse'], win=mse_win, opts=dict(\n",
    "                title='Mean Squared Error',\n",
    "                xtick=True,\n",
    "                ytick=True,\n",
    "                xlabel='training step',\n",
    "                ylabel='MSE',\n",
    "            ))\n",
    "            kld_win = viz.line(X=log['i'], Y=log['kld'], win=kld_win, opts=dict(\n",
    "                title='KL divergence',\n",
    "                xtick=True,\n",
    "                ytick=True,\n",
    "                xlabel='training step',\n",
    "                ylabel='KLD',\n",
    "            ))\n",
    "            loss_win = viz.line(X=log['i'], Y=log['loss'], win=loss_win, opts=dict(\n",
    "                title='Training loss',\n",
    "                xtick=True,\n",
    "                ytick=True,\n",
    "                xlabel='training step',\n",
    "                ylabel='loss',\n",
    "            ))\n",
    "            conv1_win = viz.image(vis_encoder_conv1(model), win=conv1_win, opts=dict(\n",
    "                title='Encoder conv1',\n",
    "                width=400,\n",
    "                height=800,\n",
    "            ))\n",
    "            conv3_win = viz.image(vis_encoder_conv3(model), win=conv3_win, opts=dict(\n",
    "                title='Encoder conv3',\n",
    "                width=1000,\n",
    "                height=1000,\n",
    "            ))\n",
    "            \n",
    "        if global_iter > 0 and global_iter % 500 == 0:\n",
    "            valid_losses.append(validation(test_loader, model))\n",
    "            valid_win = viz.line(valid_losses, win=valid_win, opts=dict(\n",
    "                title='Validation loss',\n",
    "                xtick=True,\n",
    "                ytick=True,\n",
    "                xlabel='training step',\n",
    "                ylabel='loss',\n",
    "            ))\n",
    "        \n",
    "        global_iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
